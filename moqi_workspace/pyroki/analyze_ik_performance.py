"""
IKæ€§èƒ½æ—¥å¿—åˆ†æè„šæœ¬

åˆ†æ ik_performance CSV å’Œ teleop JSON æ—¥å¿—ï¼Œæä¾›ä¼˜åŒ–å»ºè®®
"""

import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

def analyze_ik_performance(csv_path, json_path=None, output_dir=None):
    """
    åˆ†æIKæ€§èƒ½æ—¥å¿—
    
    Args:
        csv_path: ik_performance CSVæ–‡ä»¶è·¯å¾„
        json_path: teleop JSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        output_dir: è¾“å‡ºå›¾è¡¨ç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    print("=" * 80)
    print("IK æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print(f"\nğŸ“ æ•°æ®æ¥æº: {csv_path}")
    
    # è¯»å–CSVæ•°æ®
    df = pd.read_csv(csv_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # åŸºæœ¬ç»Ÿè®¡
    total_attempts = len(df)
    successful = df['solved'].sum()
    failed = total_attempts - successful
    success_rate = (successful / total_attempts) * 100
    
    print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡")
    print(f"  æ€»å°è¯•æ¬¡æ•°: {total_attempts}")
    print(f"  æˆåŠŸæ¬¡æ•°:   {successful} ({success_rate:.2f}%)")
    print(f"  å¤±è´¥æ¬¡æ•°:   {failed} ({100-success_rate:.2f}%)")
    
    # è€—æ—¶ç»Ÿè®¡
    elapsed_times = df['elapsed_ms']
    print(f"\nâ±ï¸  è€—æ—¶ç»Ÿè®¡ï¼ˆæ¯«ç§’ï¼‰")
    print(f"  å¹³å‡è€—æ—¶:   {elapsed_times.mean():.2f} ms")
    print(f"  ä¸­ä½æ•°:     {elapsed_times.median():.2f} ms")
    print(f"  æœ€å°è€—æ—¶:   {elapsed_times.min():.2f} ms")
    print(f"  æœ€å¤§è€—æ—¶:   {elapsed_times.max():.2f} ms")
    print(f"  æ ‡å‡†å·®:     {elapsed_times.std():.2f} ms")
    print(f"  95åˆ†ä½æ•°:   {elapsed_times.quantile(0.95):.2f} ms")
    print(f"  99åˆ†ä½æ•°:   {elapsed_times.quantile(0.99):.2f} ms")
    
    # æˆåŠŸvså¤±è´¥çš„è€—æ—¶å¯¹æ¯”
    if failed > 0:
        success_times = df[df['solved'] == 1]['elapsed_ms']
        fail_times = df[df['solved'] == 0]['elapsed_ms']
        
        print(f"\nğŸ“ˆ æˆåŠŸ vs å¤±è´¥å¯¹æ¯”")
        print(f"  æˆåŠŸå¹³å‡è€—æ—¶: {success_times.mean():.2f} ms")
        print(f"  å¤±è´¥å¹³å‡è€—æ—¶: {fail_times.mean():.2f} ms")
        print(f"  å·®å¼‚:         {fail_times.mean() - success_times.mean():+.2f} ms")
    
    # é¢‘ç‡ç»Ÿè®¡
    duration = (df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]).total_seconds()
    frequency = total_attempts / duration if duration > 0 else 0
    print(f"\nğŸ”„ è¿è¡Œé¢‘ç‡")
    print(f"  è¿è¡Œæ—¶é•¿:   {duration:.1f} ç§’")
    print(f"  å¹³å‡é¢‘ç‡:   {frequency:.1f} Hz")
    print(f"  ç†æƒ³å‘¨æœŸ:   {1000/frequency:.1f} ms")
    
    # è€—æ—¶åˆ†å¸ƒç»Ÿè®¡
    print(f"\nğŸ“Š è€—æ—¶åˆ†å¸ƒ")
    bins = [0, 2, 5, 10, 20, 50, float('inf')]
    labels = ['<2ms', '2-5ms', '5-10ms', '10-20ms', '20-50ms', '>50ms']
    df['time_bin'] = pd.cut(df['elapsed_ms'], bins=bins, labels=labels)
    distribution = df['time_bin'].value_counts().sort_index()
    for label, count in distribution.items():
        percentage = (count / total_attempts) * 100
        print(f"  {label:8s}: {count:5d} ({percentage:5.2f}%)")
    
    # æ€§èƒ½è¯„ä¼°
    print(f"\nğŸ¯ æ€§èƒ½è¯„ä¼°")
    avg_time = elapsed_times.mean()
    p95_time = elapsed_times.quantile(0.95)
    
    if avg_time < 5:
        print(f"  âœ… å¹³å‡è€—æ—¶ä¼˜ç§€ ({avg_time:.2f} ms < 5 ms)")
    elif avg_time < 10:
        print(f"  âœ… å¹³å‡è€—æ—¶è‰¯å¥½ ({avg_time:.2f} ms < 10 ms)")
    elif avg_time < 20:
        print(f"  âš ï¸  å¹³å‡è€—æ—¶å¯æ¥å— ({avg_time:.2f} ms < 20 ms)")
    else:
        print(f"  âŒ å¹³å‡è€—æ—¶è¿‡é•¿ ({avg_time:.2f} ms > 20 ms)")
    
    if p95_time < 10:
        print(f"  âœ… 95%è€—æ—¶ä¼˜ç§€ ({p95_time:.2f} ms < 10 ms)")
    elif p95_time < 20:
        print(f"  âœ… 95%è€—æ—¶è‰¯å¥½ ({p95_time:.2f} ms < 20 ms)")
    else:
        print(f"  âš ï¸  95%è€—æ—¶åé«˜ ({p95_time:.2f} ms > 20 ms)")
    
    if success_rate > 95:
        print(f"  âœ… æˆåŠŸç‡ä¼˜ç§€ ({success_rate:.2f}% > 95%)")
    elif success_rate > 90:
        print(f"  âœ… æˆåŠŸç‡è‰¯å¥½ ({success_rate:.2f}% > 90%)")
    elif success_rate > 80:
        print(f"  âš ï¸  æˆåŠŸç‡å¯æ¥å— ({success_rate:.2f}% > 80%)")
    else:
        print(f"  âŒ æˆåŠŸç‡è¿‡ä½ ({success_rate:.2f}% < 80%)")
    
    # ä¼˜åŒ–å»ºè®®
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®")
    
    if avg_time > 10:
        print(f"  ğŸ”§ å»ºè®®å¢å¤§ theta_step_size åˆ° 0.15 ä»¥å‡å°‘å¹³å‡è€—æ—¶")
    
    if success_rate < 90:
        print(f"  ğŸ”§ å»ºè®®å‡å° theta_step_size åˆ° 0.05 ä»¥æé«˜æˆåŠŸç‡")
        print(f"  ğŸ”§ å»ºè®®å¢åŠ  max_iterations åˆ° 80 ä»¥æé«˜æˆåŠŸç‡")
    
    if p95_time > 20:
        print(f"  ğŸ”§ 95%è€—æ—¶åé«˜ï¼Œè€ƒè™‘æ£€æŸ¥æ˜¯å¦åœ¨å·¥ä½œç©ºé—´è¾¹ç•Œé¢‘ç¹æ“ä½œ")
    
    if avg_time < 5 and success_rate > 95:
        print(f"  âœ¨ å½“å‰é…ç½®å·²ç»å¾ˆå¥½ï¼theta=0.1, steps=50 æ˜¯åˆé€‚çš„å¹³è¡¡ç‚¹")
    
    # åˆ†æå¤±è´¥æ—¥å¿—
    if json_path and Path(json_path).exists():
        print(f"\nâŒ å¤±è´¥æ¡ˆä¾‹åˆ†æ")
        with open(json_path, 'r') as f:
            failure_data = json.load(f)
        
        num_failures = len(failure_data['data'])
        print(f"  è®°å½•çš„å¤±è´¥æ¬¡æ•°: {num_failures}")
        
        if num_failures > 0:
            print(f"  å¤±è´¥ç‡: {(num_failures/total_attempts)*100:.2f}%")
            
            # åˆ†æå¤±è´¥æ—¶çš„ç›®æ ‡ä½ç½®
            failures = failure_data['data']
            if len(failures) > 0:
                left_positions = np.array([[f[5], f[6], f[7]] for f in failures])
                right_positions = np.array([[f[12], f[13], f[14]] for f in failures])
                
                left_distances = np.linalg.norm(left_positions, axis=1)
                right_distances = np.linalg.norm(right_positions, axis=1)
                
                print(f"  å·¦è‡‚å¤±è´¥æ—¶å¹³å‡è·ç¦»: {left_distances.mean():.3f} m")
                print(f"  å³è‡‚å¤±è´¥æ—¶å¹³å‡è·ç¦»: {right_distances.mean():.3f} m")
                print(f"  æœ€å¤§å·¥ä½œåŠå¾„: 0.436 m (l1+l2)")
                
                # æ£€æŸ¥æ˜¯å¦è¶…å‡ºå·¥ä½œç©ºé—´
                left_out_of_reach = (left_distances > 0.436).sum()
                right_out_of_reach = (right_distances > 0.436).sum()
                
                if left_out_of_reach > 0:
                    print(f"  âš ï¸  å·¦è‡‚æœ‰ {left_out_of_reach} æ¬¡å¤±è´¥å¯èƒ½å› è¶…å‡ºå·¥ä½œç©ºé—´")
                if right_out_of_reach > 0:
                    print(f"  âš ï¸  å³è‡‚æœ‰ {right_out_of_reach} æ¬¡å¤±è´¥å¯èƒ½å› è¶…å‡ºå·¥ä½œç©ºé—´")
    
    # ç»˜å›¾
    if output_dir:
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. è€—æ—¶æ—¶é—´åºåˆ—
        fig, axes = plt.subplots(3, 2, figsize=(15, 12))
        
        # è€—æ—¶è¶‹åŠ¿
        axes[0, 0].plot(df.index, df['elapsed_ms'], alpha=0.5, linewidth=0.5)
        axes[0, 0].axhline(y=elapsed_times.mean(), color='r', linestyle='--', label=f'Mean: {elapsed_times.mean():.2f}ms')
        axes[0, 0].axhline(y=elapsed_times.quantile(0.95), color='orange', linestyle='--', label=f'P95: {elapsed_times.quantile(0.95):.2f}ms')
        axes[0, 0].set_xlabel('Sample Index')
        axes[0, 0].set_ylabel('IK Solve Time (ms)')
        axes[0, 0].set_title('IK Solve Time Trend')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # è€—æ—¶ç›´æ–¹å›¾
        axes[0, 1].hist(df['elapsed_ms'], bins=50, edgecolor='black', alpha=0.7)
        axes[0, 1].axvline(x=elapsed_times.mean(), color='r', linestyle='--', label=f'Mean: {elapsed_times.mean():.2f}ms')
        axes[0, 1].axvline(x=elapsed_times.median(), color='g', linestyle='--', label=f'Median: {elapsed_times.median():.2f}ms')
        axes[0, 1].set_xlabel('IK Solve Time (ms)')
        axes[0, 1].set_ylabel('Frequency')
        axes[0, 1].set_title('IK Solve Time Distribution')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # æˆåŠŸç‡æ»šåŠ¨çª—å£
        window_size = 100
        df['success_rate_rolling'] = df['solved'].rolling(window=window_size).mean() * 100
        axes[1, 0].plot(df.index, df['success_rate_rolling'])
        axes[1, 0].axhline(y=success_rate, color='r', linestyle='--', label=f'Overall: {success_rate:.2f}%')
        axes[1, 0].set_xlabel('Sample Index')
        axes[1, 0].set_ylabel('Success Rate (%)')
        axes[1, 0].set_title(f'Success Rate (Rolling Window: {window_size})')
        axes[1, 0].set_ylim([0, 105])
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # ç®±çº¿å›¾
        if failed > 0:
            data_for_box = [
                df[df['solved'] == 1]['elapsed_ms'],
                df[df['solved'] == 0]['elapsed_ms']
            ]
            axes[1, 1].boxplot(data_for_box, labels=['Success', 'Failure'])
        else:
            axes[1, 1].boxplot([df['elapsed_ms']], labels=['All'])
        axes[1, 1].set_ylabel('IK Solve Time (ms)')
        axes[1, 1].set_title('Time Distribution by Result')
        axes[1, 1].grid(True, alpha=0.3)
        
        # ç´¯ç§¯åˆ†å¸ƒ
        sorted_times = np.sort(df['elapsed_ms'])
        cumulative = np.arange(1, len(sorted_times) + 1) / len(sorted_times) * 100
        axes[2, 0].plot(sorted_times, cumulative)
        axes[2, 0].axhline(y=95, color='r', linestyle='--', alpha=0.5)
        axes[2, 0].axvline(x=elapsed_times.quantile(0.95), color='r', linestyle='--', 
                          label=f'P95: {elapsed_times.quantile(0.95):.2f}ms', alpha=0.5)
        axes[2, 0].set_xlabel('IK Solve Time (ms)')
        axes[2, 0].set_ylabel('Cumulative Percentage (%)')
        axes[2, 0].set_title('Cumulative Distribution')
        axes[2, 0].legend()
        axes[2, 0].grid(True, alpha=0.3)
        
        # æ—¶é—´æ®µåˆ†æ
        df['time_bucket'] = pd.cut(df.index, bins=10)
        time_stats = df.groupby('time_bucket')['elapsed_ms'].agg(['mean', 'std'])
        axes[2, 1].errorbar(range(len(time_stats)), time_stats['mean'], yerr=time_stats['std'], 
                           marker='o', capsize=5)
        axes[2, 1].set_xlabel('Time Bucket')
        axes[2, 1].set_ylabel('Mean IK Solve Time (ms)')
        axes[2, 1].set_title('Performance Over Time')
        axes[2, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot_path = output_dir / 'ik_performance_analysis.png'
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"  âœ… ä¿å­˜å›¾è¡¨åˆ°: {plot_path}")
        plt.close()
    
    print(f"\n" + "=" * 80)
    print("åˆ†æå®Œæˆï¼")
    print("=" * 80 + "\n")
    
    return {
        'total_attempts': total_attempts,
        'success_rate': success_rate,
        'avg_time_ms': elapsed_times.mean(),
        'p95_time_ms': elapsed_times.quantile(0.95),
        'p99_time_ms': elapsed_times.quantile(0.99),
    }


if __name__ == "__main__":
    # é»˜è®¤è·¯å¾„
    log_dir = Path(__file__).parent / "log"
    
    if len(sys.argv) > 1:
        csv_path = sys.argv[1]
    else:
        # è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
        csv_files = list(log_dir.glob("ik_performance_*.csv"))
        if not csv_files:
            print("âŒ æœªæ‰¾åˆ° ik_performance CSV æ–‡ä»¶")
            sys.exit(1)
        csv_path = max(csv_files, key=lambda p: p.stat().st_mtime)
    
    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„JSONæ–‡ä»¶
    csv_stem = Path(csv_path).stem.replace('ik_performance_', 'teleop_')
    json_path = Path(csv_path).parent / f"{csv_stem}.json"
    if not json_path.exists():
        json_path = None
    
    # è¾“å‡ºç›®å½•
    output_dir = Path(csv_path).parent / "analysis"
    
    # æ‰§è¡Œåˆ†æ
    results = analyze_ik_performance(csv_path, json_path, output_dir)

